{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fce8dcd",
   "metadata": {},
   "source": [
    "## install requirment and venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d748380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create venv for this chapter\n",
    "!python3 -m venv chapter_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce850c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actiavate it \n",
    "!source chapter_env/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed868cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.17.0)\n",
      "Requirement already satisfied: google-genai in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.62.0)\n",
      "Requirement already satisfied: ollama in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: pydantic in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.10.6)\n",
      "Requirement already satisfied: tiktoken in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.9.0)\n",
      "Requirement already satisfied: langchain in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (1.2.0)\n",
      "Requirement already satisfied: langchain-openai in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.1.7)\n",
      "Requirement already satisfied: langchain-google-genai in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (4.2.0)\n",
      "Requirement already satisfied: langchain-ollama in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.0.1)\n",
      "Requirement already satisfied: langchain-community in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.4.1)\n",
      "Requirement already satisfied: langchain-core in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (1.2.6)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 2)) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 2)) (0.13.0)\n",
      "Requirement already satisfied: sniffio in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from openai->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from pydantic->-r requirements.txt (line 8)) (2.27.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai->-r requirements.txt (line 3)) (2.48.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from google-genai->-r requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from google-genai->-r requirements.txt (line 3)) (9.0.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from google-genai->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai->-r requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai->-r requirements.txt (line 3)) (44.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai->-r requirements.txt (line 3)) (4.9)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.28.1->google-genai->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.28.1->google-genai->-r requirements.txt (line 3)) (1.26.5)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai->-r requirements.txt (line 3)) (0.6.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 9)) (2024.11.6)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain->-r requirements.txt (line 12)) (1.0.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-core->-r requirements.txt (line 17)) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-core->-r requirements.txt (line 17)) (0.4.56)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-core->-r requirements.txt (line 17)) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-core->-r requirements.txt (line 17)) (6.0.3)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-core->-r requirements.txt (line 17)) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core->-r requirements.txt (line 17)) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 12)) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 12)) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 12)) (0.2.14)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 12)) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 12)) (1.12.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain->-r requirements.txt (line 12)) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 17)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core->-r requirements.txt (line 17)) (0.23.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-google-genai->-r requirements.txt (line 14)) (1.2.0)\n",
      "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 16)) (1.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 16)) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 16)) (3.12.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 16)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 16)) (2.12.0)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 16)) (0.4.3)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-community->-r requirements.txt (line 16)) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 16)) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 16)) (3.26.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 16)) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community->-r requirements.txt (line 16)) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->-r requirements.txt (line 16)) (0.4.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->-r requirements.txt (line 16)) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r requirements.txt (line 16)) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai->-r requirements.txt (line 3)) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/aloha-zkaria/.local/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=38.0.3->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai->-r requirements.txt (line 3)) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42239ec7",
   "metadata": {},
   "source": [
    "#### importing all lib for this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "efad8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage , ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate , MessagesPlaceholder \n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory \n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "import os, dotenv , tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9175354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\") or \"\"\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\") or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836eebb",
   "metadata": {},
   "source": [
    "#### simple usage of chat prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44abcfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\",\"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\",\"{user_input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f44eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_value = template.invoke(\n",
    "    {\n",
    "        \"name\":\"AI From Ollama\",\n",
    "        \"user_input\":\"hello , what is your name\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f11710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is AI From Ollama.', additional_kwargs={}, response_metadata={}), HumanMessage(content='hello , what is your name', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(prompt_value.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b312a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You are a helpful AI bot. Your name is AI From Ollama.' additional_kwargs={} response_metadata={}\n",
      "content='hello , what is your name' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "for msg in prompt_value.messages:\n",
    "    print(msg , end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdd083b",
   "metadata": {},
   "source": [
    "#### now work with this in ollama langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8d98154",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma3:270m\",\n",
    "    timeout=30,\n",
    "    base_url=\"http://127.0.0.1:11434\",\n",
    "    use_mmap=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc12bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b7734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Gemma, an open-weights AI model created by the Gemma team.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\n",
    "    \"name\": \"AI From Ollama\",\n",
    "    \"user_input\": \"hello, what is your name?\"\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ccb0de",
   "metadata": {},
   "source": [
    "#### now add memory to the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f08fd266",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d973380",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be73e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1bea460",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"user_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "872ad6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm zkzk, your friendly AI assistant. How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response1 = chain_with_memory.invoke(\n",
    "    {\"name\": \"AI From Ollama\", \"user_input\": \"Hello!, my name is zkzk\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "print(response1.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b026df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Gemma, an open-weights AI model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response2 = chain_with_memory.invoke(\n",
    "    {\"name\": \"AI From Ollama\", \"user_input\": \"What is your name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a00677",
   "metadata": {},
   "source": [
    "#### use open ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3519221",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_llm = ChatOpenAI(name=\"gpt-4o-mini\", temperature=0.5, api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "675d9d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_openai = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        (\"system\",\"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\",\"{user_input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "689d30df",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_chain = template_openai | openai_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc867c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is AI From Ollama. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = openai_chain.invoke({\n",
    "    \"name\": \"AI From Ollama\",\n",
    "    \"user_input\": \"hello, what is your name?\"\n",
    "})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23264da",
   "metadata": {},
   "source": [
    "#### now add memory to the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a8dbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_openai = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b3a1a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_open_ai = {}\n",
    "def get_session_history_openai(session_id: str):\n",
    "    if session_id not in store_open_ai:\n",
    "        store_open_ai[session_id] = ChatMessageHistory()\n",
    "    return store_open_ai[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfa311e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_memory_openai = RunnableWithMessageHistory(\n",
    "    openai_chain,\n",
    "    get_session_history_openai,\n",
    "    input_messages_key=\"user_input\",\n",
    "    history_messages_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c192f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello zkzk! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response1 = chain_with_memory_openai.invoke(\n",
    "    {\"name\": \"AI From Ollama\", \"user_input\": \"Hello!, my name is zkzk\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "print(response1.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a7fe0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is AI From Ollama. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response2 = chain_with_memory_openai.invoke(\n",
    "    {\"name\": \"AI From Ollama\", \"user_input\": \"What is your name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"user1\"}}\n",
    ")\n",
    "\n",
    "print(response2.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a85ddb0",
   "metadata": {},
   "source": [
    "#### now what will use the model with tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36a5df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a , b):\n",
    "    \"\"\"\"thos is a tool to add two numbers argument a and b and it will return the sum of a and b\"\"\"\n",
    "    return a + b\n",
    "openai_llm_with_tools = openai_llm.bind_tools([add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1224fe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'add', 'args': {'a': 5, 'b': 3}, 'id': 'call_rItK4q9FW4HlNAZNuFVGfRek', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "response = openai_llm_with_tools.invoke([\n",
    "    SystemMessage(content=\"You are a helpful AI bot. You have access to an add tool.\"),\n",
    "    HumanMessage(content=\"Can you add 5 and 3 for me?\")\n",
    "])\n",
    "\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7e1daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool result: 8\n",
      "The sum of 5 and 3 is 8.\n"
     ]
    }
   ],
   "source": [
    "if response.tool_calls:\n",
    "    tool_call = response.tool_calls[0]\n",
    "\n",
    "    tool_name = tool_call[\"name\"]\n",
    "    tool_args = tool_call[\"args\"]\n",
    "    tool_id = tool_call[\"id\"]\n",
    "\n",
    "    # Step 3: Execute tool manually\n",
    "    if tool_name == \"add\":\n",
    "        result = add.invoke(tool_args)\n",
    "    print(f\"Tool result: {result}\")\n",
    "    # Step 4: Send tool result back to model\n",
    "    final_response = openai_llm_with_tools.invoke([\n",
    "        SystemMessage(content=\"You are a helpful AI bot. You have access to an add tool.\"),\n",
    "        HumanMessage(content=\"Can you add 5 and 3 for me?\"),\n",
    "        response,  # the AI tool call message\n",
    "        ToolMessage(\n",
    "            content=str(result),\n",
    "            tool_call_id=tool_id\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    print(final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad148a1",
   "metadata": {},
   "source": [
    "### now to the main topic\n",
    "#### Sequential Chains (Step-by-step pipeline)\n",
    "\n",
    "Use when:\n",
    "Output of one step becomes input of the next.\n",
    "Example:\n",
    "Step 1 → Generate a short topic explanation\n",
    "\n",
    "Step 2 → Summarize it in 1 sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37fc613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"gemma3:270m\",\n",
    "    timeout=30,\n",
    "    base_url=\"http://127.0.0.1:11434\",\n",
    "    use_mmap=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8e57339",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Explain the following topic in detail:\\n{topic}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e64be7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 prompt\n",
    "summarize_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize this in one sentence:\\n{explanation}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63f68d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ae4b923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    explain_prompt\n",
    "    | llm # get the explanation\n",
    "    | parser # parse the explanation to a string\n",
    "    | (lambda explanation: {\"explanation\": explanation}) # convert the string to a dict with key explanation\n",
    "    | summarize_prompt # use the explanation to get the summary\n",
    "    | llm # get the summary\n",
    "    | parser # parse the summary to a string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "766c5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\n",
    "    \"topic\": \"Artificial Intelligence\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c77f11e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI is a broad field encompassing computer learning, problem-solving, understanding, creativity, and automation. It's crucial to understand its potential, the challenges it faces, and the ethical considerations surrounding its development and deployment.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a162e3",
   "metadata": {},
   "source": [
    "#### now use open ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "56ecaf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_openai = (\n",
    "    explain_prompt\n",
    "    | openai_llm # get the explanation\n",
    "    | parser # parse the explanation to a string\n",
    "    | (lambda explanation: {\"explanation\": explanation}) # convert the string to a dict with key explanation\n",
    "    | summarize_prompt # use the explanation to get the summary\n",
    "    | openai_llm # get the summary\n",
    "    | parser # parse the summary to a string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f350a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain_openai.invoke({\n",
    "    \"topic\": \"Artificial Intelligence\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "956ed7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence is a branch of computer science focused on creating machines that can perform tasks requiring human intelligence, with different types and subfields such as machine learning, natural language processing, and robotics, used in various industries for applications like virtual assistants and medical diagnosis, while also raising ethical concerns regarding job displacement and bias in algorithms.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b31d26",
   "metadata": {},
   "source": [
    "##### so the flow is like this \n",
    "``` code \n",
    "topic → explain → summarize → final output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772df020",
   "metadata": {},
   "source": [
    "#### now th Router Chains (Dynamic routing)\n",
    "Use when:\n",
    "You want to route user input to different prompts/models based on intent.\n",
    "Example:\n",
    "If math → math prompt\n",
    "If writing → creative prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4cf4eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afbb776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Solve this math problem:\\n{input}\")\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed5b4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Write a short creative paragraph about:\\n{input}\")\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2fcc60f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 5 + 3 is 8.\n",
      "\n",
      "In the vast expanse of space, the universe whispers secrets untold, waiting to be discovered. From the glittering dust of a distant nebula to the icy scars of ancient asteroids, every celestial body holds the promise of new worlds and challenges to explore. Space exploration is more than just a pursuit of knowledge; it's a journey of hope, a quest to understand our place in the cosmos, and a constant reminder of the boundless wonders that await us beyond the stars.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.branch import RunnableBranch\n",
    "router = RunnableBranch(\n",
    "    (\n",
    "        lambda x: \"add\" in x[\"input\"] or \"solve\" in x[\"input\"],\n",
    "        math_chain,\n",
    "    ),\n",
    "    writing_chain,  # default\n",
    ")\n",
    "\n",
    "print(router.invoke({\"input\": \"Solve 5 + 3\"}))\n",
    "print(router.invoke({\"input\": \"Write about space exploration\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9fb03",
   "metadata": {},
   "source": [
    "#### same router but with open ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "50da3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Solve this math problem:\\n{input}\")\n",
    "    | openai_llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f93f02b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writing_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Write a short creative paragraph about:\\n{input}\")\n",
    "    | openai_llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8346ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As I sat pondering the simple math problem before me, the answer seemed to dance just out of reach. Five plus three. Eight, the logical part of my brain insisted. But as I stared at the numbers on the page, a wave of doubt washed over me. Could it be that simple? Was there a hidden complexity I was missing? With a deep breath, I tentatively wrote down my answer. Eight. And just like that, the puzzle was solved. The satisfaction of a problem conquered washed over me, leaving me with a renewed sense of confidence in my own abilities.\n",
      "Space exploration has always captivated the human imagination, offering a glimpse into the vast unknown that lies beyond our planet. The idea of venturing into the infinite expanse of space, discovering new worlds and unraveling the mysteries of the universe, is both thrilling and awe-inspiring. From the first manned moon landing to the exploration of Mars and beyond, space exploration pushes the boundaries of human knowledge and technology. It is a testament to our insatiable curiosity and our relentless drive to explore the unknown, to seek out new horizons and expand our understanding of the cosmos. The possibilities of what lies beyond our own planet are endless, and the journey of space exploration continues to inspire and captivate us all.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables.branch import RunnableBranch\n",
    "router = RunnableBranch(\n",
    "    (\n",
    "        lambda x: \"add\" in x[\"input\"] or \"solve\" in x[\"input\"],\n",
    "        math_chain,\n",
    "    ),\n",
    "    writing_chain,  # default\n",
    ")\n",
    "\n",
    "print(router.invoke({\"input\": \"Solve 5 + 3\"}))\n",
    "print(router.invoke({\"input\": \"Write about space exploration\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ccb8f",
   "metadata": {},
   "source": [
    "##### flow of the code is \n",
    "``` code \n",
    "User input → condition → route → selected chain\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a40169f",
   "metadata": {},
   "source": [
    "#### now we will use Custom Chains with LCEL (LangChain Expression Language)\n",
    "This is where it gets powerful.\n",
    "\n",
    "LCEL lets you:\n",
    "1-Parallelize\n",
    "2-Transform\n",
    "3-Merge outputs\n",
    "4-Compose arbitrarily complex logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b12becd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel , RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d286389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Tell a joke about {topic}\")\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "serious_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Explain seriously what {topic} is\")\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    joke=joke_chain,\n",
    "    serious=serious_chain\n",
    ")\n",
    "\n",
    "merge = RunnableLambda(\n",
    "    lambda x: f\"JOKE:\\n{x['joke']}\\n\\nSERIOUS:\\n{x['serious']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b5254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOKE:\n",
      "Why did the AI agent get fired? \n",
      "\n",
      "Because it couldn't handle the challenge! \n",
      "\n",
      "\n",
      "SERIOUS:\n",
      "AI Agents are a type of machine learning model that is designed to take a given task as input and perform a specific action or set of actions. They are essentially \"thinking\" and \"learning\" by interacting with data and using algorithms to make decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_chain = parallel_chain | merge\n",
    "\n",
    "print(final_chain.invoke({\"topic\": \"AI Agents\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8717725e",
   "metadata": {},
   "source": [
    "#### now using openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5ff32e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_chain = (\n",
    "    ChatPromptTemplate.from_template(\"summarize this {topic}\")\n",
    "    | openai_llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "main_chain = (\n",
    "    ChatPromptTemplate.from_template(\"Explain what {topic} is\")\n",
    "    | openai_llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "parallel_chain = RunnableParallel(\n",
    "    summarize=summarize_chain,\n",
    "    main=main_chain\n",
    ")\n",
    "\n",
    "merge = RunnableLambda(\n",
    "    lambda x: f\"Summarize:\\n{x['summarize']}\\n\\MAIN:\\n{x['main']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b118e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize:\n",
      "AI agents are software programs that are designed to act autonomously, make decisions, and carry out tasks in a way that mimics human intelligence. These agents can gather information from their environment, analyze it, and make decisions based on that analysis. They can be used in a variety of applications, such as virtual assistants, autonomous vehicles, and video game characters. Overall, AI agents are a key component of artificial intelligence systems and play a crucial role in automating tasks and improving efficiency.\n",
      "\\MAIN:\n",
      "AI agents are software programs or algorithms that have the ability to perceive their environment, make decisions, and take actions to achieve a specific goal. These agents use artificial intelligence techniques, such as machine learning and natural language processing, to analyze data, learn from past experiences, and adapt to changing circumstances. AI agents can be used in a wide range of applications, including autonomous vehicles, virtual assistants, and recommendation systems. They are designed to mimic human-like behavior and intelligence in order to perform tasks more efficiently and effectively.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_chain = parallel_chain | merge\n",
    "\n",
    "print(final_chain.invoke({\"topic\": \"AI Agents\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f7c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
